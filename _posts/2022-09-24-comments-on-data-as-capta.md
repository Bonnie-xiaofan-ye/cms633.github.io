---
layout: post
published: true
category: commentary
title: Comments on "Data as Capta"
author: Danny Kessler
tags:
  - Digital_Humanities
---
##Drucker’s _Data as Capta_

**Humanities Approaches to Graphical Display 

The observation itself, which is what we're visualizing, is not the same as the phenomena itself. We're measuring our observations of a phenomena, not the phenomena itself. We need to remember this, and not think that we are measuring objective data. Regarding the author’s claim that, “at best, we need to take on the challenge of developing graphical expressions rooted in and appropriate to interpretative activity,” I don't see it as a problem. However, we need to visualize the data while making clear, verbally, that the measurements are of observations. In a way similar to how self-report surveys are based in individual perspective and perception, so are these measurements.

In this chapter, the author seems to be thinking that the social sciences claim universal transparency, which I find problematic. There is always an element of perception, and an element of uncertainty, even in what's reported as fact. In my experience, at least, social scientists are careful to make clear that these are observations made with certain limitations. As the author later points out: "Social scientists may divide between realist and constructivist foundations for their research, but none are naïve when it comes to the rhetorical character of statistics." To take this in another direction: it is for readers to read (for example, the limitations section of the paper - although admittedly it is carefully concealed) and know that what they're reading is biased, one way or the other, as perhaps all methods somehow are, since they are carried out by humans. "

I take issue with this quote: "To reiterate what I said above, the sheer power of the graphical display of “information visualization” (and its novelty within a humanities community newly enthralled with the toys of data mining and display) seems to have produced a momentary blindness among practitioners who." If I understand her correctly, I can't disagree more. All academic discussion, all description, is purely illustrative, and cannot be seen "as reality." I'm deeply frustrated by the author's apparent claims that data visualization, in itself, claims to represent objective reality, or that we as practitioners view it as such. It is, in all cases, for audiences to be wary. The onus cannot be on scholars to make readers realize that perception is perception, and that illustration is not reality. I also strongly disagree with her assertion that "quantitative approaches... operate on claims of certainty." If they do so, to any degree, then so do humanists: but we all, in our academic and industry silos, are more or less blind to the ways in which those in other fields understand and describe their own epistemologies. In other words: even statisticians are wary of taking statistics at face value.

I do agree, however, with her claim, that the "authority of humanistic knowledge in a culture increasingly beset by claims of quantitative approaches" is, as perceived, at stake. But we shouldn't forget that the social and behavioral sciences, while rather "new" as independent fields of inquiry, have used qualitative approaches for as long as they have existed. What makes the humanities "feel" loose, to me, is that the humanities study the creations of humans--their illustrations of their experiences (paintings, novels, great works of art, etc.), and so there is this idea, albeit an issue, that they are too abstract to have an impact on (for example) public policy. But how do we change this status quoue? If anything, I don't yet see how the use of quantitative visualization methods in the humanities jeapordizes their credibility -- although I understand her fear that, to some, this might seem to accept a shortcoming of humanistic inquiry. I will use a hammer to build a house because it is the right tool for the job--not as a depiction of my own inability to hammer a nail with my bare hand. The humanities are limited in their methods. So are the social sciences. So are the hard sciences. Anyway: that's my diatribe.

I accept that “humanistic methods are counter to the idea of reliably repeatable experiments or standard metrics that assume observer independent phenomena,” but I also believe that they don’t have to be. And while all things are connected and relative, there are, always, variables that exist in one place and are not subject to the direct conditions of another, except at atomic scales at which their mention is unnecessary. However, I agree that, “by definition, a humanistic approach is centered in the experiential, subjective conditions of interpretation.” I also agree that “we need to conceive of every metric “as a factor of X,” where X is a point of view, agenda, assumption, presumption, or simply a convention.”

I enjoyed her visualization of “hours as a function of time pressures,” and I believe this is an apt point. Really, too, we could relabel the x axis so we aren’t looking at hours, but behaviors, because the hours themselves may not be appropriate delineations if we’re talking about functions of time pressure. For example, maybe your train is at 6:45, and once you’re on your train your time pressure diminishes significantly until about 8:25am, 5 minutes before your next meeting. In any case, she makes a fair observation. 

In general, I find her visualizations interesting and worth mentioning. I don’t find her thoughts on graphic displays to be unique to the digital humanities, and I find the real issue to be scholarly publishers of quantitative (or mixed-methods) content, who could scoff at the notion of presenting information in these ways. That’s a problem, to me, because these visualization approaches have merit, especially as they relate to psychological factors of perception. However, some of these approaches make “comparing results” across studies by different scholars almost impossible, and so they are, almost, selfish and overly individualistic, since cross-comparison is incredibly important when using science in public policy.  

**Time as Temporality

I like the notion of “temporality [equaling] time as a factor of X where X is any variable (anxiety, foreshadowing, regret, reconsideration, narration, etc.).” I also see a lot of value in her sequential representations of event sequences, which could be applied in narratology and elsewhere where we have (very ineffective) linear models of events. In general, I’d like to do a separate analysis of these representations and explore the kinds of uses they’d have in my work. I also think that, in general, her recommended approaches are sound; in some cases, I imagine that her applications could be accompanied by a sort of “legend” that can help translate the findings into the terms used by other scientists “for comparison,” although this would not always function. 

**Space as Spatiality

This chapter is also interesting, and with a similar point, but noting the added challenge of translating affect into spatial perceptions. As the author points out: “When we shift from modeling experience to find graphical expressions for the representation of experience, the complexity of the problem increases.” This causes a problem for both spatial and temporal capta. But furthermore, “modeling the temporal relations among documents about temporal experience (imagine letters, emails, text messages, or diary entries from these various bus riders, only some of which is date stamped), gives rise to yet further ambiguities and complexities.” In the cases of these descriptions, Drucker’s illustrations are maybe best applied in single-case design studies of individual experiences. What further happens, for example, when we try contextualizing these days across people with different perceptions, different observer-dependencies? That seems to be an essential limitation of the proposed approaches. Her example of a sailing ship, for example, and its perspectives warping, would be difficult to visualize or represent for multiple ships.  

**Conclusions regarding this larger reading

In the current culture war waged between the sciences and humanities, I fear that the present work, in its contemptuousness, seems to me to be adding fuel to the fire unnecessarily while making sweeping assumptions about the sciences just as she feels (and I agree) many scientists make sweeping assumptions about humanists. Overall, I disagree with much that Drucker has to say about the nature of data and, in general, about how the sciences function. But I do think her ideas are very much worth wrestling with, especially in their potential to result in what I might call “a subjectivity statement” in published literature, similar to what has become a tradition of a “statement of limitations.” I don’t think that scientists, for the most part, see their work as objective or their illustrations as sheer truth. But maybe all authors should release subjectivity statements alongside their work to make clear that the work is subjective, and to describe what and how this may have manifested in that particular paper or study. This seems reasonable to me. As a final note: I also find her contribution of observer-dependency essential to the representation of any data, or capta.
